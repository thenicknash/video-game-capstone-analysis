{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Video Game Data EDA</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_games_data_df = pd.read_csv('../data/vgchartz_games_webscrape.csv', dtype=str)\n",
    "expanded_games_data_df = pd.read_csv('../data/games_data_expanded.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepping the data for merging</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are making necessary modifications in order to perform a merger between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the release date column to be YYYY-MM-DD\n",
    "raw_games_data_df['release_date'] = pd.to_datetime(raw_games_data_df['release_date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "raw_games_data_df['last_update_date'] = pd.to_datetime(raw_games_data_df['last_update_date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Rename the columns in the expanded dataset to match the raw dataset\n",
    "expanded_games_data_df = expanded_games_data_df.rename(columns={\n",
    "    'Name': 'game',\n",
    "})\n",
    "\n",
    "# Dropping all records that are a series and not a game \n",
    "raw_games_data_df = raw_games_data_df[~raw_games_data_df['platform'].str.contains('Series')]\n",
    "\n",
    "# Strip out any whitespace for every column in both datasets\n",
    "raw_games_data_df = raw_games_data_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "expanded_games_data_df = expanded_games_data_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Merging the 2 datasets</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are merging the valuable datapoints from the expanded dataset (sourced from Kaggle) into the original dataset (webscraped from VGChartz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_games_data_new_columns_df = expanded_games_data_df[['game', 'Genre']]\n",
    "expanded_games_data_meta_count_df = expanded_games_data_df[['game', 'Genre', 'Critic_Count', 'Critic_Score', 'User_Count', 'User_Score', 'Rating']]\n",
    "\n",
    "raw_games_data_df = pd.merge(raw_games_data_df, expanded_games_data_meta_count_df, on='game', how='left')\n",
    "raw_games_data_df.drop_duplicates(subset=['game'], keep='first', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rename some of the raw data columns that were just merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Genre column to be genre\n",
    "raw_games_data_df = raw_games_data_df.rename(columns={\n",
    "    'Genre': 'genre',\n",
    "    'Critic_Count': 'metacritic_count',\n",
    "    'Critic_Score': 'metacritic_score',\n",
    "    'User_Count': 'metacritic_user_count',\n",
    "    'User_Score': 'metacritic_user_score',\n",
    "    'Rating': 'esrb_rating'\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exploratory data analysis findings</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x2022; `critic_score` and `user_score` are wildly inconsistent in their appearances. Thus, we will ignore and drop these columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x2022; `total_shipped` represents volume of sales, not revenue or profit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x2022; Unfortunately, the individual breakdown of the sales by geographical region is not available. Perhaps I can supplement this data with a different dataset as a stretch goal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x2022; `last_update_date` is essentially useless for this project. We will drop this column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x2022; With the remaining columns, I will be able to glean enough information to answer the initial question posed - at least on a surface level. More data will be needed to answer the question in more depth."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x2022; If the `total_shipped` column is empty, but the `total_sales` column is not, we will update the `total_shipped` column with the value in the `total_sales` column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data cleaning and manipulation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23577 games without sales data. We will drop these records now.\n",
      "The total number of games in the dataset is now 15679.\n",
      "We are dropping the games that sold less than 100,000. The total number of games in the dataset is now 14735.\n"
     ]
    }
   ],
   "source": [
    "# Replace the null values in total_shipped with the values in total_sales\n",
    "raw_games_data_df['total_shipped'] = np.where(raw_games_data_df['total_shipped'].isnull() & raw_games_data_df['total_sales'].notnull(), raw_games_data_df['total_sales'], raw_games_data_df['total_shipped'])\n",
    "gta_game_df = raw_games_data_df[raw_games_data_df['game'] == 'Grand Theft Auto V']\n",
    "n_games_without_sales_data = raw_games_data_df['total_shipped'].isnull().sum()\n",
    "\n",
    "print(f'There are {n_games_without_sales_data} games without sales data. We will drop these records now.')\n",
    "\n",
    "# Drop the rows where total_shipped is null\n",
    "raw_games_data_df = raw_games_data_df.dropna(subset=['total_shipped'])\n",
    "\n",
    "print(f'The total number of games in the dataset is now {len(raw_games_data_df)}.')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "try:\n",
    "    raw_games_data_df = raw_games_data_df.drop(\n",
    "        columns=[\n",
    "            'last_update_date',\n",
    "            'critic_score',\n",
    "            'user_score'\n",
    "        ]\n",
    "    )\n",
    "except KeyError:\n",
    "    print('Unnecessary columns have already been dropped.')\n",
    "\n",
    "# Strip out the 'm' from the end of the total_shipped column\n",
    "try:\n",
    "    raw_games_data_df['total_shipped'] = raw_games_data_df['total_shipped'].str.replace('m', '')\n",
    "except AttributeError:\n",
    "    print('The total_shipped column has already been converted to a float.')\n",
    "\n",
    "# Turn the total_shipped column into a float\n",
    "raw_games_data_df['total_shipped'] = raw_games_data_df['total_shipped'].astype(float)\n",
    "\n",
    "# Remove all rows where the total_shipped value is 0 (less than 100,000 is the true value)\n",
    "raw_games_data_df = raw_games_data_df[raw_games_data_df['total_shipped'] > 0]\n",
    "\n",
    "print(f'We are dropping the games that sold less than 100,000. The total number of games in the dataset is now {len(raw_games_data_df)}.')\n",
    "\n",
    "# Remove 'tbd' values from the metacritic_user_score column\n",
    "try:\n",
    "    raw_games_data_df = raw_games_data_df[raw_games_data_df['metacritic_user_score'] != 'tbd']\n",
    "except TypeError:\n",
    "    print('The tbd values have already been removed from the metacritic_user_score column.')\n",
    "\n",
    "# Multiply the metacritic_user_score column by 10 to get the correct value (1-100)\n",
    "raw_games_data_df['metacritic_user_score'] = raw_games_data_df['metacritic_user_score'].astype(float) * 10\n",
    "\n",
    "# Adding a new column to expand the ESRB ratings into full words\n",
    "raw_games_data_df['esrb_rating_full'] = raw_games_data_df['esrb_rating'].map({\n",
    "    'E': 'Everyone',\n",
    "    'E10+': 'Everyone 10+',\n",
    "    'T': 'Teen',\n",
    "    'M': 'Mature',\n",
    "    'AO': 'Adults Only',\n",
    "    'EC': 'Early Childhood',\n",
    "    'K-A': 'Kids to Adults'\n",
    "})\n",
    "\n",
    "# TODO: I need to rerank all of the games based on their current order in the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Write scrubbed data to csv</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the cleaned dataset to a csv file\n",
    "raw_games_data_df.to_csv('../data/normalized_games_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
